# å¯¼å…¥å¿…è¦çš„åº“
import gradio as gr  # Gradioç”¨äºåˆ›å»ºWebç•Œé¢
from together import Together  # Together AIçš„Pythonå®¢æˆ·ç«¯
import tempfile  # ç”¨äºåˆ›å»ºä¸´æ—¶æ–‡ä»¶
from PIL import Image  # ç”¨äºå›¾åƒå¤„ç†
import os  # ç”¨äºæ–‡ä»¶å’Œç›®å½•æ“ä½œ
import requests  # ç”¨äºå‘é€HTTPè¯·æ±‚
from io import BytesIO  # ç”¨äºå¤„ç†äºŒè¿›åˆ¶æ•°æ®
import logging  # ç”¨äºæ—¥å¿—è®°å½•
import base64  # ç”¨äºBase64ç¼–ç /è§£ç 
import zipfile  # ç”¨äºåˆ›å»ºZIPæ–‡ä»¶
import time  # ç”¨äºæ—¶é—´ç›¸å…³æ“ä½œ
import random  # ç”¨äºç”Ÿæˆéšæœºæ•°

# è®¾ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆå§‹åŒ–Together AIå®¢æˆ·ç«¯
client = Together()

# å®šä¹‰å¯ç”¨çš„å›¾ç”Ÿå›¾æ¨¡å‹
IMG2IMG_MODELS = {
    "FLUX.1-depth": "black-forest-labs/FLUX.1-depth",  # æ·±åº¦å›¾å¼•å¯¼çš„å›¾åƒç”Ÿæˆ
    "FLUX.1-canny": "black-forest-labs/FLUX.1-canny",  # è¾¹ç¼˜æ£€æµ‹å¼•å¯¼çš„å›¾åƒç”Ÿæˆ
    "FLUX.1-redux": "black-forest-labs/FLUX.1-redux"   # é€šç”¨å›¾åƒç”Ÿæˆ
}

# å®šä¹‰å¯ç”¨çš„æ–‡ç”Ÿå›¾æ¨¡å‹
TEXT2IMG_MODELS = {
    "FLUX.1-dev": "black-forest-labs/FLUX.1-dev",        # å¼€å‘ç‰ˆæ¨¡å‹
    "FLUX.1-schnell": "black-forest-labs/FLUX.1-schnell",  # å¿«é€Ÿç”Ÿæˆæ¨¡å‹
    "FLUX.1.1-pro": "black-forest-labs/FLUX.1.1-pro"      # ä¸“ä¸šç‰ˆæ¨¡å‹
}

# å„æ¨¡å‹çš„ç‰¹å®šå‚æ•°è®¾ç½®
MODEL_PARAMS = {
    # å›¾ç”Ÿå›¾æ¨¡å‹å‚æ•°
    "black-forest-labs/FLUX.1-depth": {"min_steps": 4, "max_steps": 50, "default_steps": 28},
    "black-forest-labs/FLUX.1-canny": {"min_steps": 4, "max_steps": 50, "default_steps": 28},
    "black-forest-labs/FLUX.1-redux": {"min_steps": 4, "max_steps": 50, "default_steps": 28},
    
    # æ–‡ç”Ÿå›¾æ¨¡å‹å‚æ•°
    "black-forest-labs/FLUX.1-dev": {"min_steps": 25, "max_steps": 50, "default_steps": 28},
    "black-forest-labs/FLUX.1-schnell": {"min_steps": 4, "max_steps": 50, "default_steps": 12},
    "black-forest-labs/FLUX.1.1-pro": {"min_steps": 1, "max_steps": 10, "default_steps": 4}
}

def encode_image_to_base64(image):
    """
    å°†PILå›¾åƒå¯¹è±¡è½¬æ¢ä¸ºbase64ç¼–ç çš„å­—ç¬¦ä¸²
    
    Args:
        image: PIL Imageå¯¹è±¡
        
    Returns:
        str: base64ç¼–ç çš„å›¾åƒæ•°æ®URL
    """
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"

def save_images_as_zip(images):
    """
    å°†å¤šå¼ å›¾ç‰‡ä¿å­˜ä¸ºZIPæ–‡ä»¶
    
    Args:
        images: PIL Imageå¯¹è±¡åˆ—è¡¨
        
    Returns:
        str: ZIPæ–‡ä»¶çš„è·¯å¾„ï¼Œå¦‚æœå‡ºé”™åˆ™è¿”å›None
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.join(os.getcwd(), "outputs")
    os.makedirs(output_dir, exist_ok=True)
    
    # ä½¿ç”¨æ—¶é—´æˆ³åˆ›å»ºå”¯ä¸€çš„æ–‡ä»¶å
    timestamp = int(time.time())
    zip_filename = f"generated_images_{timestamp}.zip"
    zip_path = os.path.join(output_dir, zip_filename)
    
    try:
        with zipfile.ZipFile(zip_path, 'w') as zipf:
            for i, img in enumerate(images):
                img_byte_arr = BytesIO()
                img.save(img_byte_arr, format='PNG')
                img_byte_arr = img_byte_arr.getvalue()
                zipf.writestr(f"image_{i+1}.png", img_byte_arr)
        
        return zip_path
    except Exception as e:
        logger.error(f"Error creating ZIP file: {e}")
        if os.path.exists(zip_path):
            os.remove(zip_path)
        return None

def process_image2image(image, model_name, prompt, width, height, steps, num_images, seed):
    """
    å¤„ç†å›¾ç”Ÿå›¾è¯·æ±‚ï¼Œå°†è¾“å…¥å›¾ç‰‡è½¬æ¢ä¸ºæ–°çš„å›¾ç‰‡
    
    Args:
        image: è¾“å…¥å›¾ç‰‡ï¼ˆPIL Imageå¯¹è±¡ï¼‰
        model_name: é€‰æ‹©çš„æ¨¡å‹åç§°
        prompt: æ–‡æœ¬æç¤ºè¯
        width: è¾“å‡ºå›¾ç‰‡å®½åº¦
        height: è¾“å‡ºå›¾ç‰‡é«˜åº¦
        steps: ç”Ÿæˆæ­¥æ•°
        num_images: ç”Ÿæˆå›¾ç‰‡æ•°é‡
        seed: éšæœºç§å­
        
    Returns:
        tuple: (ç”Ÿæˆçš„å›¾ç‰‡åˆ—è¡¨, ZIPæ–‡ä»¶è·¯å¾„, çŠ¶æ€æ¶ˆæ¯)
    """
    # æ£€æŸ¥å¿…è¦çš„è¾“å…¥
    if image is None:
        return [None] * num_images, None, "è¯·ä¸Šä¼ å›¾ç‰‡"
    if model_name != "FLUX.1-redux" and not prompt:
        return [None] * num_images, None, "è¯·è¾“å…¥æç¤ºè¯ï¼ˆä»…FLUX.1-reduxæ¨¡å‹å¯é€‰ï¼‰"
    
    try:
        # å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64æ ¼å¼
        image_base64 = encode_image_to_base64(image)
        logger.info("å›¾ç‰‡å·²è½¬æ¢ä¸ºbase64æ ¼å¼")
        
        model_id = IMG2IMG_MODELS[model_name]
        
        # å‡†å¤‡APIè°ƒç”¨å‚æ•°
        api_params = {
            "model": model_id,
            "width": width,
            "height": height,
            "steps": min(steps, MODEL_PARAMS[model_id]["max_steps"]),
            "n": num_images,
            "image_url": image_base64,
            "prompt": prompt if (prompt or model_name != "FLUX.1-redux") else "[]",
            "seed": seed if seed > 0 else random.randint(1, 10000)
        }
        
        logger.info(f"ä½¿ç”¨æ¨¡å‹ {model_name} ç”Ÿæˆ {num_images} å¼ å›¾ç‰‡")
        imageCompletion = client.images.generate(**api_params)
        
        # å¤„ç†ç”Ÿæˆçš„å›¾ç‰‡
        generated_images = []
        for i, data in enumerate(imageCompletion.data):
            result_url = data.url
            logger.info(f"ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡ {i+1}/{num_images}")
            
            response = requests.get(result_url)
            if response.status_code == 200:
                generated_image = Image.open(BytesIO(response.content))
                generated_images.append(generated_image)
            else:
                logger.error(f"ä¸‹è½½å›¾ç‰‡ {i+1} å¤±è´¥ã€‚çŠ¶æ€ç : {response.status_code}")
        
        if not generated_images:
            return [None] * num_images, None, "ç”Ÿæˆå›¾ç‰‡å¤±è´¥"
        
        # ä¿å­˜ä¸ºZIPæ–‡ä»¶
        zip_path = save_images_as_zip(generated_images)
        
        # ç¡®ä¿è¿”å›åˆ—è¡¨é•¿åº¦ç¬¦åˆè¦æ±‚
        while len(generated_images) < num_images:
            generated_images.append(None)
        
        return (
            generated_images,
            zip_path,
            f"æˆåŠŸä½¿ç”¨ {model_name} ç”Ÿæˆäº† {len(generated_images)} å¼ å›¾ç‰‡ï¼"
        )
            
    except Exception as e:
        error_msg = f"é”™è¯¯: {str(e)}"
        logger.error(error_msg)
        return [None] * num_images, None, error_msg

def process_text2image(prompt, model_name, width, height, steps, num_images, seed):
    """
    å¤„ç†æ–‡ç”Ÿå›¾è¯·æ±‚ï¼Œæ ¹æ®æ–‡æœ¬æç¤ºè¯ç”Ÿæˆå›¾ç‰‡
    
    Args:
        prompt: æ–‡æœ¬æç¤ºè¯
        model_name: é€‰æ‹©çš„æ¨¡å‹åç§°
        width: è¾“å‡ºå›¾ç‰‡å®½åº¦
        height: è¾“å‡ºå›¾ç‰‡é«˜åº¦
        steps: ç”Ÿæˆæ­¥æ•°
        num_images: ç”Ÿæˆå›¾ç‰‡æ•°é‡
        seed: éšæœºç§å­
        
    Returns:
        tuple: (ç”Ÿæˆçš„å›¾ç‰‡åˆ—è¡¨, ZIPæ–‡ä»¶è·¯å¾„, çŠ¶æ€æ¶ˆæ¯)
    """
    # æ£€æŸ¥å¿…è¦çš„è¾“å…¥
    if not prompt:
        return [None] * num_images, None, "è¯·è¾“å…¥æç¤ºè¯"
    
    try:
        model_id = TEXT2IMG_MODELS[model_name]
        model_params = MODEL_PARAMS[model_id]
        
        # æ ¹æ®æ¨¡å‹è°ƒæ•´æ­¥æ•°
        if steps == 28:  # å¦‚æœæ˜¯é»˜è®¤å€¼
            steps = model_params["default_steps"]
        else:
            # ç¡®ä¿æ­¥æ•°åœ¨æ¨¡å‹çš„é™åˆ¶èŒƒå›´å†…
            steps = max(model_params["min_steps"], min(steps, model_params["max_steps"]))
        
        # å‡†å¤‡APIè°ƒç”¨å‚æ•°
        api_params = {
            "model": model_id,
            "prompt": prompt,
            "width": width,
            "height": height,
            "steps": steps,
            "n": num_images,
            "seed": seed if seed > 0 else random.randint(1, 10000)
        }
        
        logger.info(f"ä½¿ç”¨æ¨¡å‹ {model_name} ç”Ÿæˆ {num_images} å¼ å›¾ç‰‡ï¼ˆæ­¥æ•°: {steps}ï¼‰")
        try:
            imageCompletion = client.images.generate(**api_params)
        except Exception as api_error:
            error_msg = str(api_error)
            if "credit card" in error_msg.lower():
                raise Exception(
                    "æ­¤æ¨¡å‹éœ€è¦ä¿¡ç”¨å¡éªŒè¯ã€‚"
                    "è¯·åœ¨ https://api.together.xyz/settings/billing æ·»åŠ ä¿¡ç”¨å¡"
                )
            raise  # é‡æ–°æŠ›å‡ºå…¶ä»–APIé”™è¯¯
        
        # å¤„ç†ç”Ÿæˆçš„å›¾ç‰‡
        generated_images = []
        for i, data in enumerate(imageCompletion.data):
            result_url = data.url
            logger.info(f"ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡ {i+1}/{num_images}")
            
            response = requests.get(result_url)
            if response.status_code == 200:
                generated_image = Image.open(BytesIO(response.content))
                generated_images.append(generated_image)
            else:
                logger.error(f"ä¸‹è½½å›¾ç‰‡ {i+1} å¤±è´¥ã€‚çŠ¶æ€ç : {response.status_code}")
        
        if not generated_images:
            return [None] * num_images, None, "ç”Ÿæˆå›¾ç‰‡å¤±è´¥"
        
        # ä¿å­˜ä¸ºZIPæ–‡ä»¶
        zip_path = save_images_as_zip(generated_images)
        
        # ç¡®ä¿è¿”å›åˆ—è¡¨é•¿åº¦ç¬¦åˆè¦æ±‚
        while len(generated_images) < num_images:
            generated_images.append(None)
        
        return (
            generated_images,
            zip_path,
            f"æˆåŠŸä½¿ç”¨ {model_name} ç”Ÿæˆäº† {len(generated_images)} å¼ å›¾ç‰‡ï¼"
        )
            
    except Exception as e:
        error_msg = str(e)
        logger.error(f"é”™è¯¯: {error_msg}")
        return [None] * num_images, None, f"é”™è¯¯: {error_msg}"

def get_image_prompts(image):
    """
    åˆ†æå›¾ç‰‡å¹¶ç”Ÿæˆç›¸ä¼¼çš„AIè‰ºæœ¯æç¤ºè¯
    
    Args:
        image: PIL Imageå¯¹è±¡
        
    Returns:
        str: ç”Ÿæˆçš„æç¤ºè¯æˆ–é”™è¯¯æ¶ˆæ¯
    """
    if image is None:
        return "è¯·å…ˆä¸Šä¼ å›¾ç‰‡"
    
    try:
        # å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64æ ¼å¼
        buffered = BytesIO()
        image.save(buffered, format="JPEG")
        img_str = base64.b64encode(buffered.getvalue()).decode()
        
        # å‡†å¤‡å¯¹è¯æ¶ˆæ¯
        client = Together()
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIè‰ºæœ¯ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ†æå›¾ç‰‡å¹¶æä¾›èƒ½é‡æ–°åˆ›å»ºç±»ä¼¼å›¾ç‰‡çš„AIè‰ºæœ¯æç¤ºè¯ã€‚è¯·å§‹ç»ˆæä¾›3ä¸ªæç¤ºè¯ï¼Œåˆ†åˆ«å…³æ³¨ä¸åŒæ–¹é¢å¦‚é£æ ¼ã€æ„å›¾å’Œç»†èŠ‚ã€‚"
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "åˆ†æè¿™å¼ å›¾ç‰‡å¹¶å†™å‡º3ä¸ªä¸åŒçš„AIè‰ºæœ¯æç¤ºè¯ï¼Œæ¯ä¸ªæç¤ºè¯å…³æ³¨ä¸åŒçš„æ–¹é¢ã€‚æ ¼å¼ï¼š1. [æç¤ºè¯1] 2. [æç¤ºè¯2] 3. [æç¤ºè¯3]"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{img_str}"
                        }
                    }
                ]
            }
        ]

        # è°ƒç”¨APIç”Ÿæˆæç¤ºè¯
        response = client.chat.completions.create(
            model="meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
            messages=messages,
            temperature=0.7,
            top_p=0.7,
            top_k=50,
            repetition_penalty=1,
            stop=["<|eot_id|>", "<|eom_id|>"],
            max_tokens=512
        )
        
        result = response.choices[0].message.content.strip()
        
        # æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«æ‹’ç»æˆ–é”™è¯¯ä¿¡æ¯
        error_phrases = [
            "i'm not", "cannot", "sorry", "unable", 
            "don't", "do not", "won't", "will not",
            "inappropriate", "not appropriate"
        ]
        
        if any(phrase in result.lower() for phrase in error_phrases):
            return "æ— æ³•åˆ†ææ­¤å›¾ç‰‡ï¼Œè¯·å°è¯•ä¸Šä¼ å…¶ä»–å›¾ç‰‡ã€‚æç¤ºï¼šä¸Šä¼ AIç”Ÿæˆçš„å›¾ç‰‡æ•ˆæœæ›´å¥½ã€‚"
            
        # å¦‚æœå“åº”å¤ªçŸ­ï¼Œå¯èƒ½ä¸æ˜¯æœ‰æ•ˆçš„æç¤ºè¯
        if len(result.split()) < 10:
            return "ç”Ÿæˆçš„æç¤ºè¯æ— æ•ˆï¼Œè¯·é‡è¯•æˆ–ä¸Šä¼ å…¶ä»–å›¾ç‰‡"
            
        return result
    except Exception as e:
        return f"ç”Ÿæˆæç¤ºè¯æ—¶å‡ºé”™: {str(e)}"

# å®šä¹‰ç•Œé¢æ ·å¼
css = """
.gradio-container {
    font-family: 'Helvetica Neue', Arial, sans-serif !important;
}
.gallery {
    margin: 20px 0;
    display: flex;
    flex-wrap: wrap;
    gap: 10px;
}
.gallery img {
    cursor: pointer;
}
.app-title {
    text-align: center;
    margin-bottom: 2em;
    color: #2a4858;
}
.app-title h1 {
    font-size: 2.5em;
    margin-bottom: 0.2em;
}
.app-title p {
    font-size: 1.1em;
    color: #666;
}
"""

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(theme=gr.themes.Soft(), css=css) as demo:
    # æ·»åŠ é¡µé¢æ ‡é¢˜
    with gr.Column():
        gr.HTML(
            """
            <div class="app-title">
                <h1>ğŸŒŠ Together Flux Studio</h1>
                <p>Powered by Together AI</p>
            </div>
            """
        )
    
    # ç”¨äºåœ¨æ ‡ç­¾é¡µä¹‹é—´ä¼ é€’é€‰ä¸­å›¾ç‰‡çš„çŠ¶æ€å˜é‡
    selected_image = gr.State(None)
    
    with gr.Tabs():
        # æ–‡ç”Ÿå›¾æ ‡ç­¾é¡µ
        with gr.Tab("Text to Image"):
            with gr.Row():
                # å·¦ä¾§æ§åˆ¶é¢æ¿
                with gr.Column():
                    # æ–‡æœ¬è¾“å…¥æ¡†
                    text2img_prompt = gr.Textbox(
                        label="Enter your prompt",
                        placeholder="Describe the image you want to generate...",
                        lines=2
                    )
                    # æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
                    text2img_model = gr.Dropdown(
                        choices=list(TEXT2IMG_MODELS.keys()),
                        value="FLUX.1-dev",
                        label="Select Model (Credit Card Required)"
                    )
                    
                    # å›¾ç‰‡å°ºå¯¸æ§åˆ¶
                    with gr.Row():
                        text2img_width = gr.Slider(
                            minimum=0,
                            maximum=1792,
                            value=1024,
                            step=64,
                            label="Width"
                        )
                        text2img_height = gr.Slider(
                            minimum=0,
                            maximum=1792,
                            value=1024,
                            step=64,
                            label="Height"
                        )
                    
                    # ç”Ÿæˆå‚æ•°æ§åˆ¶
                    with gr.Row():
                        text2img_steps = gr.Slider(
                            minimum=1,
                            maximum=50,
                            value=28,
                            step=1,
                            label="Steps (will adjust based on model)"
                        )
                        text2img_num = gr.Slider(
                            minimum=1,
                            maximum=10,
                            value=1,
                            step=1,
                            label="Number of Images"
                        )
                    
                    # éšæœºç§å­æ§åˆ¶
                    text2img_seed = gr.Slider(
                        minimum=0,
                        maximum=10000,
                        value=0,
                        step=1,
                        label="Seed (0 for random)"
                    )
                    
                    # ç”ŸæˆæŒ‰é’®
                    text2img_btn = gr.Button("Generate Images", variant="primary")
                
                # å³ä¾§å›¾ç‰‡å±•ç¤ºåŒº
                with gr.Column():
                    # å›¾ç‰‡ç”»å»Š
                    text2img_gallery = gr.Gallery(
                        label="ç”Ÿæˆçš„å›¾ç‰‡ï¼ˆé€‰æ‹©ä¸€å¼ æƒ³è¦å¤„ç†çš„å›¾ç‰‡ï¼‰",
                        show_label=True,
                        elem_id="text2img_gallery",
                        columns=2,
                        rows=2,
                        height="auto",
                        preview=True,
                        allow_preview=True,
                        selected_index=None
                    )
                    # æ“ä½œæŒ‰é’®å’Œä¸‹è½½åŒº
                    with gr.Row():
                        send_to_img2img = gr.Button("å‘é€åˆ°å›¾ç‰‡ç”Ÿæˆé¡µé¢", variant="secondary", scale=2)
                        text2img_download = gr.File(
                            label="ä¸‹è½½æ‰€æœ‰å›¾ç‰‡(ZIP)",
                            file_count="single",
                            scale=1
                        )
                    # çŠ¶æ€æ˜¾ç¤º
                    text2img_status = gr.Textbox(label="çŠ¶æ€", interactive=False)
        
        # å›¾ç”Ÿå›¾æ ‡ç­¾é¡µ
        with gr.Tab("Image to Image"):
            with gr.Row():
                # å·¦ä¾§æ§åˆ¶é¢æ¿
                with gr.Column():
                    # å›¾ç‰‡è¾“å…¥
                    input_image = gr.Image(
                        type="pil",
                        label="ä¸Šä¼ å›¾ç‰‡æˆ–ä»æ–‡å­—ç”Ÿæˆçš„å›¾ç‰‡ä¸­é€‰æ‹©ï¼ˆå…ˆåœ¨æ–‡å­—ç”Ÿæˆé¡µé¢ç”Ÿæˆå›¾ç‰‡ï¼Œç‚¹å‡»æƒ³è¦çš„å›¾ç‰‡åä¼šè‡ªåŠ¨ä¼ åˆ°è¿™é‡Œï¼‰"
                    )
                    # æ¨¡å‹é€‰æ‹©
                    img2img_model = gr.Dropdown(
                        choices=list(IMG2IMG_MODELS.keys()),
                        value="FLUX.1-depth",
                        label="Select Model"
                    )
                    # æç¤ºè¯è¾“å…¥
                    img2img_prompt = gr.Textbox(
                        label="Enter your prompt",
                        placeholder="Describe how you want to transform the image... (optional for FLUX.1-redux)",
                        lines=2
                    )
                    
                    # å›¾ç‰‡å°ºå¯¸æ§åˆ¶
                    with gr.Row():
                        img2img_width = gr.Slider(
                            minimum=0,
                            maximum=1792,
                            value=1024,
                            step=64,
                            label="Width"
                        )
                        img2img_height = gr.Slider(
                            minimum=0,
                            maximum=1792,
                            value=1024,
                            step=64,
                            label="Height"
                        )
                    
                    # ç”Ÿæˆå‚æ•°æ§åˆ¶
                    with gr.Row():
                        img2img_steps = gr.Slider(
                            minimum=4,
                            maximum=50,
                            value=28,
                            step=1,
                            label="Steps"
                        )
                        img2img_num = gr.Slider(
                            minimum=1,
                            maximum=10,
                            value=1,
                            step=1,
                            label="Number of Images"
                        )
                    
                    # éšæœºç§å­æ§åˆ¶
                    img2img_seed = gr.Slider(
                        minimum=0,
                        maximum=10000,
                        value=0,
                        step=1,
                        label="Seed (0 for random)"
                    )
                    
                    # ç”ŸæˆæŒ‰é’®
                    img2img_btn = gr.Button("Generate Images", variant="primary")
                
                # å³ä¾§å›¾ç‰‡å±•ç¤ºåŒº
                with gr.Column():
                    # å›¾ç‰‡ç”»å»Š
                    img2img_gallery = gr.Gallery(
                        label="Generated Images",
                        show_label=True,
                        elem_id="img2img_gallery",
                        columns=[2],
                        rows=[2],
                        height="auto"
                    )
                    # ä¸‹è½½åŒº
                    img2img_download = gr.File(
                        label="Download All Images (ZIP)",
                        file_count="single"
                    )
                    # çŠ¶æ€æ˜¾ç¤º
                    img2img_status = gr.Textbox(label="Status", interactive=False)
        
        # æç¤ºè¯åˆ†ææ ‡ç­¾é¡µ
        with gr.Tab("æç¤ºè¯è¯†åˆ«"):
            with gr.Row():
                # å·¦ä¾§å›¾ç‰‡ä¸Šä¼ åŒº
                with gr.Column(scale=1):
                    prompt_image = gr.Image(
                        type="pil",
                        label="ä¸Šä¼ å›¾ç‰‡",
                        sources=["upload"],
                        height=400
                    )
                    analyze_btn = gr.Button("åˆ†æå›¾ç‰‡", variant="primary")
                
                # å³ä¾§ç»“æœæ˜¾ç¤ºåŒº
                with gr.Column(scale=1):
                    prompt_output = gr.Textbox(
                        label="å¯èƒ½çš„æç¤ºè¯",
                        placeholder="ä¸Šä¼ å›¾ç‰‡å¹¶ç‚¹å‡»åˆ†ææŒ‰é’®è·å–æç¤ºè¯...",
                        lines=6,
                        interactive=False
                    )
                    prompt_status = gr.Textbox(
                        label="çŠ¶æ€",
                        visible=False,
                        interactive=False
                    )
    
    # äº‹ä»¶å¤„ç†å‡½æ•°
    def on_select_text2img(gallery):
        """
        å¤„ç†ä»å›¾åº“ä¸­é€‰æ‹©å›¾ç‰‡çš„äº‹ä»¶
        
        Args:
            gallery: å›¾åº“ç»„ä»¶çš„å½“å‰çŠ¶æ€
            
        Returns:
            é€‰ä¸­çš„å›¾ç‰‡æˆ–None
        """
        if gallery is not None and isinstance(gallery, list) and len(gallery) > 0:
            selected = gallery[0]  # è·å–é€‰ä¸­çš„ç¬¬ä¸€å¼ å›¾ç‰‡
            if isinstance(selected, tuple):
                # å¦‚æœæ˜¯å…ƒç»„ï¼Œè¿”å›ç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆå›¾ç‰‡æ•°æ®ï¼‰
                return selected[0]
            return selected
        return None

    # æ³¨å†Œäº‹ä»¶å¤„ç†å™¨
    # ä»æ–‡ç”Ÿå›¾é¡µé¢å‘é€å›¾ç‰‡åˆ°å›¾ç”Ÿå›¾é¡µé¢
    send_to_img2img.click(
        fn=on_select_text2img,
        inputs=[text2img_gallery],
        outputs=[input_image],
    )
    
    # å›¾ç”Ÿå›¾ç”ŸæˆæŒ‰é’®ç‚¹å‡»äº‹ä»¶
    img2img_btn.click(
        fn=process_image2image,
        inputs=[
            input_image,
            img2img_model,
            img2img_prompt,
            img2img_width,
            img2img_height,
            img2img_steps,
            img2img_num,
            img2img_seed
        ],
        outputs=[img2img_gallery, img2img_download, img2img_status]
    )
    
    # æ–‡ç”Ÿå›¾ç”ŸæˆæŒ‰é’®ç‚¹å‡»äº‹ä»¶
    text2img_btn.click(
        fn=process_text2image,
        inputs=[
            text2img_prompt,
            text2img_model,
            text2img_width,
            text2img_height,
            text2img_steps,
            text2img_num,
            text2img_seed
        ],
        outputs=[text2img_gallery, text2img_download, text2img_status]
    )
    
    def on_analyze_click(image, status):
        """
        å¤„ç†å›¾ç‰‡åˆ†ææŒ‰é’®ç‚¹å‡»äº‹ä»¶
        
        Args:
            image: è¾“å…¥å›¾ç‰‡
            status: å½“å‰çŠ¶æ€
            
        Returns:
            tuple: (ç”Ÿæˆçš„æç¤ºè¯, çŠ¶æ€æ¶ˆæ¯)
        """
        if image is None:
            return None, "è¯·å…ˆä¸Šä¼ å›¾ç‰‡"
        try:
            prompts = get_image_prompts(image)
            return prompts, None
        except Exception as e:
            return None, f"åˆ†æå‡ºé”™: {str(e)}"

    # å›¾ç‰‡åˆ†ææŒ‰é’®ç‚¹å‡»äº‹ä»¶
    analyze_btn.click(
        fn=on_analyze_click,
        inputs=[prompt_image, prompt_status],
        outputs=[prompt_output, prompt_status],
        api_name=False
    )

# ç¨‹åºå…¥å£ç‚¹
if __name__ == "__main__":
    # å¯åŠ¨Gradioåº”ç”¨
    demo.launch(
        server_name="127.0.0.1",  # æœ¬åœ°æœåŠ¡å™¨
        show_error=True,          # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        share=False              # ä¸åˆ›å»ºå…¬å…±é“¾æ¥
    )